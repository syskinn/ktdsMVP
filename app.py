#ì‹œê°í™” ë° ì›¹ì•± êµ¬ì„±
import streamlit as st
import altair as alt
# ë°ì´í„° ë° íŒŒì¼ ì²˜ë¦¬
import pandas as pd
import openai
import os
import io
# í™˜ê²½ë³€ìˆ˜ ë° ìœ í‹¸ë¦¬í‹°
from dotenv import load_dotenv
from collections import Counter
# íƒ€ì… ì„ ì–¸ ë° ë°ì´í„° ëª¨ë¸ë§
from typing import List, Literal, Dict
from pydantic import BaseModel, Field
# LangChain ë° OpenAI ì—°ë™
from langchain.prompts import ChatPromptTemplate
from langchain_openai import AzureChatOpenAI
from defect_classification import defect_classify

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
AZURE_OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AZURE_ENDPOINT = os.getenv("OPENAI_AZURE_ENDPOINT")

# LLM ì„¤ì •
llm = AzureChatOpenAI(
    azure_deployment="gpt-4.1",
    api_version="2024-12-01-preview",
    azure_endpoint=AZURE_ENDPOINT,
    temperature=0.0,
    api_key=AZURE_OPENAI_API_KEY
)

# ë©”ì¸í™”ë©´ Streamlit ì„¤ì •
st.markdown(
    """
    <div style="text-align:center; padding:10px; border:2px solid #4CAF50; border-radius:10px;">
        <h2> ğŸ“Š KT ìŠ¤ë§ˆíŠ¸í° ìƒìš©í’ˆì§ˆ ëª¨ë‹ˆí„°ë§</h2>
        <h3> [ VOC ê°ì •ë¶„ì„ / ê²°í•¨ìœ í˜• / ì£¼ìš”í‚¤ì›Œë“œ ]</h3>
    </div>
    """,
    unsafe_allow_html=True
)

# --- VOC ê°ì •ë¶„ì„ ì •ì˜ ---
class Sentiment(BaseModel):
    sentiment: Literal["ê¸ì •", "ë¶€ì •"] = Field(description="sentiment of a sentence")

system_template = """\
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì¥ì˜ ê°ì •ì„ 'ê¸ì •'ì¸ì§€ 'ë¶€ì •'ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ê°ì • ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì¥ì˜ ê°ì •ì„ ì •í™•íˆ íŒë‹¨í•˜ì„¸ìš”:
{examples}
"""

prompt_sentiment = ChatPromptTemplate.from_messages([
    ("system", system_template),
    ("user", "{text}")
])

senti_chain = prompt_sentiment | llm.with_structured_output(Sentiment)

def senti_classify(user_input: str, examples: List[Dict[str, str]]) -> str:
    try:
        examples_str = "\n\n".join(
            f"ë¬¸ì¥: {ex['text']}\nê°ì •: {ex['label']}"
            for ex in examples
        )
        result = senti_chain.invoke({
            "text": user_input,
            "examples": examples_str
        })
        return result.sentiment
    except Exception as e:
        return f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

sample_examples = [
    {"text": "ì•ˆë…•í•˜ì„¸ìš” í˜„ì¬ ë…¸íŠ¸ í˜ì´ì§€ ëª¨ì•„ë³´ê¸° ê°€ 2í–‰ ê¸°ì¤€ì¸ë° ì•„ë˜ ì²˜ëŸ¼ 4í–‰ì´ë‚˜ 5í–‰ìœ¼ë¡œ ë°”ë€Œë©´ ì¢‹ê² ì–´ìš” ê·¸ëŸ¼ í˜ì´ì§€ ë°°ì—´ ìˆ˜ì •í•˜ê±°ë‚˜ í•œ ëˆˆì— ë³´ê¸° ë” í¸í•  ê±° ê°™ì•„ìš”", "label": "ê¸ì •"},
    {"text": "ì•ˆë…•í•˜ì„¸ìš” ì‚¼ì„±ë…¸íŠ¸ì—ì„œ ë°‘ì¤„ ê·¸ì„ë•Œ ì§ì„  ì´ì™¸ì—ë„ ë¬¼ê²° ëª¨ì–‘ì´ë‚˜ ì ì„  ëª¨ì–‘ ë°‘ì¤„ ì´ ìˆìœ¼ë©´ ì¢‹ê² ì–´ìš”", "label": "ê¸ì •"},
    {"text": "ê°¤ëŸ­ì‹œ s24 one ul8 ì•ˆë“œë¡œì´ë“œ 16 ì–¸ì œ ì°¸ì—¬ ê°€ëŠ¥í• ì§€ ì´ë²ˆ ì–¸íŒ© ìœ íŠœë¸Œ ì‹œì²­í–ˆëŠ”ë° ì§€ê¸ˆ ì›Œì¹˜7 ìš¸íŠ¸ë¼ ë””ìì¸ ì¢‹íƒ€ê³  ë³´ë„¤ìš”", "label": "ê¸ì •"},
    {"text": "ë‹¤ìŒ ê°¤ëŸ­ì‹œ s26 ìš¸íŠ¸ë¼ ì¹©ì…‹ í€„ê²€ SíŒ¬ íƒ‘ì œ ë˜ê¸¸ ë°”ë¼ë„¤ìš” ë‚´ë…„ ê°¤ëŸ­ì‹œ ì–¸íŒ© ìœ íŠœë¸Œ ì˜ìƒ ê¸°ë‹¤ë¦´ê²Œìš”", "label": "ê¸ì •"},
    {"text": "ì•„ì‹¸! ì†ì „ë“± í•˜ë‚˜ ë” ìƒê²¼ë„¤ìš”~ ì•„ì˜¤ *** ì”¬ë‚˜~", "label": "ê¸ì •"},
    {"text": "ìš¸íŠ¸ë¼ ì“°ì‹œëŠ” ë¶„ë“¤ oul8 ë² íƒ€ë²„ì „ ì–´ë– ì‹ ê°€ìš”?", "label": "ê¸ì •"},
    {"text": "ì´ ì„œë¹„ìŠ¤ ì •ë§ í¸ë¦¬í•˜ê³  ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.", "label": "ê¸ì •"},
    {"text": "ì•±ì´ ìê¾¸ ë ‰ ê±¸ë ¤ì„œ ì‚¬ìš©í•˜ê¸° ë¶ˆí¸í–ˆì–´ìš”.", "label": "ë¶€ì •"},
    {"text": "[S24U] ì—…ë°ì´íŠ¸ í›„ ê·¹ì‹¬í•œ ë°œì—´", "label": "ë¶€ì •"},
    {"text": "OneUI 7.0 ì—…ë°ì´íŠ¸ í›„ AIì§€ìš°ê°œ ê¸°ëŠ¥ì„ ì“¸ ìˆ˜ ì—†ê²Œ ë¨ (S22)", "label": "ë¶€ì •"},
    {"text": "7.0 ì—…ë°ì´íŠ¸ ì´í›„ ì•ŒëŒ ì•ˆìš¸ë¦¼", "label": "ë¶€ì •"},
    {"text": "One UI 7.0 ì—…ë°ì´íŠ¸ í›„ ê²Œì´ë° í—ˆë¸Œë‘ ê²Œì„ ì €ë§Œ íŠ•ê¸°ë‚˜ìš”", "label": "ë¶€ì •"},
    {"text": "S23FE ê¸°ì¢… í° í„°ì¹˜ê°€ ëª‡ë¶„ë’¤ì— í„°ì¹˜ê°€ ì•ˆë¼ê³  ë¨¹í†µì´ ë©ë‹ˆë‹¤ ë„ì™€ì£¼ì„¸ì—¬", "label": "ë¶€ì •"},
    {"text": "s23ì…ë‹ˆë‹¤. ê²½ê³  ì„¤ì •ì„ í•´ë„ ê²½ê³  ì•Œë¦¼ì´ ì•ˆ ëœ¨ëŠ”ë° ì–´ë–»ê²Œ í•˜ë©´ ëœ¨ê²Œ í•  ìˆ˜ ìˆì„ê¹Œìš”? ì°¨ë‹¨ ì„¤ì •í•´ ë†“ìœ¼ë©´ ì°¨ë‹¨ì€ ì˜ ë©ë‹ˆë‹¤.", "label": "ë¶€ì •"},
    {"text": "AOD í•­ìƒí‘œì‹œë¡œ í•´ë„ ëª‡ ì´ˆë’¤ êº¼ì§", "label": "ë¶€ì •"},
    {"text": "S25 ìš¸íŠ¸ë¼ ê°€ë” ì¤‘ê°„ìœ„ì— ë²„ë²… ê±°ë¦¬ë˜ë° í°ì´ ë¶ˆëŸ‰ê°™ì€ë° êµí™˜í• ë ¤ë©´ ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "label": "ë¶€ì •"},
    {"text": "S24 Ultra ì‚¬ìš©ìì…ë‹ˆë‹¤. ì œì–´ì„¼í„°ê°€ ê°„í˜¹ ë‘ë²ˆì§¸ ì´ë¯¸ì§€ì²˜ëŸ¼ ë³€í•˜ê³  ë³€í•œ ë¶€ë¶„ì€ í„°ì¹˜ê°€ ì•ˆë©ë‹ˆë‹¤.", "label": "ë¶€ì •"},
    {"text": "now brief ë‹¤ìš´ë°›ì•˜ëŠ”ë° now barì—ëŠ” ì•ˆëœ¨ë„¤ìš”", "label": "ë¶€ì •"},
    {"text": "7.0ì—…ê·¸ë ˆì´ë“œí•˜ê³ ë‚˜ì„œ ì•ŒëŒì„¤ì • ë¸”ë£¨íˆ¬ìŠ¤ì—°ê²° ìƒë‹¨ë°”ì— í‘œì‹œ ì•ˆë˜ì–´ ë¬´ì§€ ë¶ˆí¸í•©ë‹ˆë‹¤. ì˜ˆì „ìœ¼ë¡œ ê°ˆìˆ˜ì—†ë‚˜ìš”? 07. 10. 17:49", "label": "ë¶€ì •"},
    {"text": "ìœ„ì ¯ë„ í¬ê¸°ë¥¼ ì¤„ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ì—…ë°ì´íŠ¸ í›„ ìœ„ì ¯ë“¤ì´ ë‹¤ ì»¤ì ¸ì„œ ê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ í™ˆ í™”ë©´ ë ˆì´ì•„ì›ƒ ë‹¤ ê¹¨ì ¸ë²„ë¦¬ê³  ë¶ˆí¸í•¨ë§Œ ëŠ˜ì–´ì„œ ê´œíˆ í–ˆë‹¤ ì‹¶ë„¤ìš”", "label": "ë¶€ì •"},
    {"text": "4k 60 í”„ë ˆì„ ì˜ìƒ ì¬ìƒí•˜ë©´ ë¬´ì¡°ê±´ì´ë¼ í•´ë„ ì¢‹ì„ë§Œí¼ ëšëš ëŠê¸°ë©´ì„œ ë²„ë²…ê±°ë¦¬ëŠ”ë° ì €ë§Œ ì´ëŸ°ê°€ìš”?", "label": "ë¶€ì •"},
    {"text": "S25 ì‹œê³„ì•±ì´ ì‚¬ë¼ì¡Œì–´ìš”.", "label": "ë¶€ì •"},

]


# --- VOC ìœ í˜•ë¶„ì„ ì •ì˜ defect_classification í˜¸ì¶œ ---


# --- VOC í‚¤ì›Œë“œ ì¶”ì¶œ ì •ì˜ ---
class KeywordExtraction(BaseModel):
    keywords: List[str] = Field(description="ë¬¸ì¥ì—ì„œ ì¶”ì¶œëœ í’ˆì§ˆ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸")

system_prompt_kw = """\
ë‹¹ì‹ ì€ ë¬¸ì¥ì—ì„œ í’ˆì§ˆ ì´ìŠˆ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ì„ ë”°ë¥´ì„¸ìš”:
- 'í™”ë©´', 'í„°ì¹˜', 'ì†ë„', 'ì¶©ì „', 'ì˜¤ë¥˜', 'ë²„ë²…ì„' ë“± í’ˆì§ˆ ê´€ë ¨ ëª…í™•í•œ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
- ë‹¨ë§ëª…, ë¸Œëœë“œëª…(ì˜ˆ: ê°¤ëŸ­ì‹œ, ë²„ì¦ˆ, S24)ì€ ì œì™¸
- 'ì¢‹ë‹¤', 'ì‹«ë‹¤', 'ë¶ˆí¸í•˜ë‹¤' ë“± ê°ì •ì Â·ì¶”ìƒì  í‘œí˜„ì€ ì œì™¸
- ê²°ê³¼ëŠ” í‚¤ì›Œë“œë§Œ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸(List[str])ë¡œ ë°˜í™˜
ì˜ˆì‹œ:
ë¬¸ì¥: "í™”ë©´ì´ ìê¾¸ êº¼ì§€ê³  í„°ì¹˜ê°€ ì•ˆ ë¨¹í˜€ìš”"
ê²°ê³¼: ["í™”ë©´", "êº¼ì§", "í„°ì¹˜", "ë¯¸ì‘ë™"]
"""

prompt_kw = ChatPromptTemplate.from_messages([
    ("system", system_prompt_kw),
    ("user", "{text}")
])

keyword_chain = prompt_kw | llm.with_structured_output(KeywordExtraction)

def extract_keywords(user_input: str) -> List[str]:
    if not user_input.strip():
        return ["ì…ë ¥ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤."]
    try:
        result = keyword_chain.invoke({"text": user_input})
        return result.keywords
    except openai.error.AuthenticationError:
        return ["ì¶”ì¶œ ì‹¤íŒ¨: API í‚¤ ì¸ì¦ ì˜¤ë¥˜"]
    except openai.error.OpenAIError as e:
        return [f"ì¶”ì¶œ ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {str(e)}"]
    except Exception as e:
        return [f"ì¶”ì¶œ ì‹¤íŒ¨: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ - {str(e)}"]


# --- Streamlit UI (ì‚¬ì´ë“œë°” + ë©”ì¸) ---
# Streamlitì˜ session_stateë¥¼ í™œìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥
if "processed_df" not in st.session_state:
    st.session_state.processed_df = None

st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ì—‘ì…€(.xlsx/.xls) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx", "xls"])

if uploaded_file:
    if st.session_state.processed_df is None:  # ë¶„ì„ì´ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê²½ìš°
        df = pd.read_excel(uploaded_file)

        # 'ë‚´ìš©' í•„ë“œë¥¼ 'strReview'ë¡œ ë³€ê²½
        if "ë‚´ìš©" in df.columns:
            df.rename(columns={"ë‚´ìš©": "strReview"}, inplace=True)

        text_col = next(
            (col for col in df.columns if col.lower() == "strreview" or "text" in col.lower() or "ì˜ê²¬" in col),
            None
        )

        if not text_col:
            st.error("âŒ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'strReview', 'text', 'ì˜ê²¬', 'ë‚´ìš©' ë“±ì„ ì»¬ëŸ¼ëª…ì— í¬í•¨í•´ì£¼ì„¸ìš”.")
        else:
            st.success(f"âœ… ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼: **{text_col}**")

            with st.spinner("ğŸ“Š ë¶„ì„ ì¤‘..."):
                df["strEmotion"] = df[text_col].apply(lambda x: senti_classify(str(x), sample_examples))
                df["strMainCategory"] = df[text_col].apply(lambda x: defect_classify(str(x)))
                df["strKeyword"] = df[text_col].apply(lambda x: extract_keywords(str(x)))

            st.session_state.processed_df = df  # ë¶„ì„ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
    else:
        df = st.session_state.processed_df  # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜´

    # ê²°ê³¼ Preview
    st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(10), use_container_width=True)

    # ê°ì • ë¶„í¬ ì°¨íŠ¸
    st.subheader("ğŸ˜Š ê°ì • ë¶„í¬")
    emo_counts = df["strEmotion"].value_counts().reset_index()
    emo_counts.columns = ['ê°ì •', 'ê±´ìˆ˜']
    emo_chart = alt.Chart(emo_counts).mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5).encode(
        x=alt.X('ê°ì •:N', title='ê°ì •'),
        y=alt.Y('ê±´ìˆ˜:Q', title='ë¹ˆë„ìˆ˜'),
        color=alt.Color('ê°ì •:N', legend=None, scale=alt.Scale(scheme='category10'))
    ).properties(width=400, height=300)
    emo_text = emo_chart.mark_text(
        align='center',
        baseline='bottom',
        dy=-5
    ).encode(text='ê±´ìˆ˜:Q')
    st.altair_chart(emo_chart + emo_text, use_container_width=False)

    # ê²°í•¨ ìœ í˜• ë¶„í¬ ì°¨íŠ¸
    st.subheader("ğŸ› ï¸ ê²°í•¨ìœ í˜• ë¶„í¬")
    defect_counts = df["strMainCategory"].value_counts().reset_index()
    defect_counts.columns = ['ê²°í•¨ìœ í˜•', 'ê±´ìˆ˜']
    defect_chart = alt.Chart(defect_counts).mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5).encode(
        x=alt.X('ê²°í•¨ìœ í˜•:N', sort='-y', title='ê²°í•¨ìœ í˜•'),
        y=alt.Y('ê±´ìˆ˜:Q', title='ë¹ˆë„ìˆ˜'),
        color=alt.Color('ê²°í•¨ìœ í˜•:N', legend=None, scale=alt.Scale(scheme='tableau10'))
    ).properties(width=400, height=300)
    defect_text = defect_chart.mark_text(
        align='center',
        baseline='bottom',
        dy=-5
    ).encode(text='ê±´ìˆ˜:Q')
    st.altair_chart(defect_chart + defect_text, use_container_width=False)

    # í‚¤ì›Œë“œ Top 5 í‘œ ì¶œë ¥
    st.subheader("ğŸ”‘ í‚¤ì›Œë“œ Top 5")
    all_keywords = sum(df["strKeyword"], [])
    top5 = Counter(all_keywords).most_common(5)
    top5_df = pd.DataFrame(top5, columns=["í‚¤ì›Œë“œ", "ì–¸ê¸‰ ìˆ˜"])
    st.table(top5_df.style.set_properties(**{'font-size': '16px', 'text-align': 'center'}))

    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    output = io.BytesIO()
    df.to_excel(output, index=False, engine="openpyxl")
    st.download_button(
        label="ğŸ“¥ ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=output.getvalue(),
        file_name="ë¶„ì„ê²°ê³¼.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:
    st.info("â¬…ï¸ ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")